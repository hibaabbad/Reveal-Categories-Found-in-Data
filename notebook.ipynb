{"cells":[{"source":"![wordcloud](wordcloud.png)\n\nAs a Data Scientist working for a mobile app company, you usually find yourself applying product analytics to better understand user behavior, uncover patterns, and reveal insights to identify the great and not-so-great features. Recently, the number of negative reviews has increased on Google Play, and as a consequence, the app's rating has been decreasing. The team has requested you to analyze the situation and make sense of the negative reviews.\n\nIt's up to you to apply K-means clustering from scikit-learn and NLP techniques through NLTK to sort text data from negative reviews in the Google Play Store into categories!\n\n## The Data\n\nA dataset has been shared with a sample of reviews and their respective scores (from 1 to 5) in the Google Play Store. A summary and preview are provided below.\n\n# reviews.csv\n\n| Column     | Description              |\n|------------|--------------------------|\n| `'content'` | Content (text) of each review. |\n| `'score'` | Score assigned to the review by the user as an integer (from 1 to 5). |","metadata":{},"id":"c79a760b-d438-41bb-b1a1-2578773c0fe0","cell_type":"markdown"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1721153445573,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize"},"id":"48172b7a-d771-435b-a6fe-c99134ac5eba","cell_type":"code","execution_count":101,"outputs":[]},{"source":"# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1721153445621,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"id":"8a6577b0-9915-43c7-b1db-b0c106a71cca","cell_type":"code","execution_count":102,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":102}]},{"source":"# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1721153445675,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()","outputsMetadata":{"0":{"height":217,"type":"dataFrame"}}},"id":"7fbf3e3f-0526-4f53-908e-0bf9913f213d","cell_type":"code","execution_count":103,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"content","type":"string"},{"name":"score","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"content":["I cannot open the app anymore","I have been begging for a refund from this app for over a month and nobody is replying me","Very costly for the premium version (approx Indian Rupees 910 per year). Better to download the premium version of this app from apkmos website and use it. Microsoft to do list app is far more better.","Used to keep me organized, but all the 2020 UPDATES have made a mess of things !!! Y cudn't u leave well enuf alone ??? Guess ur techies feel the need to keep making changes to justify continuing to collect their salary !!! ðŸ¤¤ðŸ¤¤ðŸ¤¤","Dan Birthday Oct 28"],"score":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"                                             content  score\n0                      I cannot open the app anymore      1\n1  I have been begging for a refund from this app...      1\n2  Very costly for the premium version (approx In...      1\n3  Used to keep me organized, but all the 2020 UP...      1\n4                                Dan Birthday Oct 28      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I cannot open the app anymore</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I have been begging for a refund from this app...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Very costly for the premium version (approx In...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Used to keep me organized, but all the 2020 UP...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dan Birthday Oct 28</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":103}]},{"source":"# Your code starts here\n# Cells are free! Use as many as you need ;)\nreviews['score'].value_counts()\n","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1721153445729,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Your code starts here\n# Cells are free! Use as many as you need ;)\nreviews['score'].value_counts()\n","outputsMetadata":{"0":{"height":217,"type":"dataFrame"}}},"id":"3b2697f7-e85a-4a11-bfbb-59af07b89c75","cell_type":"code","execution_count":104,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"score","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[5,4,1,2,3],"score":[2879,2775,2506,2344,1991]}},"total_rows":5,"truncation_type":null},"text/plain":"5    2879\n4    2775\n1    2506\n2    2344\n3    1991\nName: score, dtype: int64"},"metadata":{},"execution_count":104}]},{"source":"negative_reviews=reviews[(reviews['score']==1) | (reviews['score']==2)]\nnegative_reviews.head()\n\nfrom nltk.stem import PorterStemmer\n\nstemmer=PorterStemmer()\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    text=text.lower()\n    tokens=[token for token in word_tokenize(text) if token.isalpha()]\n    filtered_stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n    \n    return ' '.join(filtered_stemmed_tokens)\n    \npreprocessed_reviews = pd.DataFrame({\n    'content': negative_reviews['content'].apply(preprocess_text)\n})\npreprocessed_reviews.head()\n    ","metadata":{"executionCancelledAt":null,"executionTime":2851,"lastExecutedAt":1721153448580,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"negative_reviews=reviews[(reviews['score']==1) | (reviews['score']==2)]\nnegative_reviews.head()\n\nfrom nltk.stem import PorterStemmer\n\nstemmer=PorterStemmer()\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    text=text.lower()\n    tokens=[token for token in word_tokenize(text) if token.isalpha()]\n    filtered_stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n    \n    return ' '.join(filtered_stemmed_tokens)\n    \npreprocessed_reviews = pd.DataFrame({\n    'content': negative_reviews['content'].apply(preprocess_text)\n})\npreprocessed_reviews.head()\n    ","outputsMetadata":{"0":{"height":217,"type":"dataFrame"}}},"cell_type":"code","id":"c20fd855-b7f7-424a-8493-20d761d115f0","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"content","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"content":["open app anymor","beg refund app month nobodi repli","costli premium version approx indian rupe per year better download premium version app apkmo websit use microsoft list app far better","use keep organ updat made mess thing cud u leav well enuf alon guess ur techi feel need keep make chang justifi continu collect salari","dan birthday oct"]}},"total_rows":5,"truncation_type":null},"text/plain":"                                             content\n0                                    open app anymor\n1                  beg refund app month nobodi repli\n2  costli premium version approx indian rupe per ...\n3  use keep organ updat made mess thing cud u lea...\n4                                   dan birthday oct","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>open app anymor</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>beg refund app month nobodi repli</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>costli premium version approx indian rupe per ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>use keep organ updat made mess thing cud u lea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dan birthday oct</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":105}],"execution_count":105},{"source":"tfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform([x for x in preprocessed_reviews['content']])\nprint(tfidf_matrix.shape)","metadata":{"executionCancelledAt":null,"executionTime":71,"lastExecutedAt":1721153448651,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"tfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform([x for x in preprocessed_reviews['content']])\nprint(tfidf_matrix.shape)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"7ff512a5-0bb7-4ffb-b63c-c5ba1305fc4f","outputs":[{"output_type":"stream","name":"stdout","text":"(4850, 4986)\n"}],"execution_count":106},{"source":"km= KMeans(n_clusters=5)\nkm.fit(tfidf_matrix)\ncategories= km.labels_.tolist()\npreprocessed_reviews['cluster'] = km.labels_","metadata":{"executionCancelledAt":null,"executionTime":238,"lastExecutedAt":1721153448889,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"km= KMeans(n_clusters=5)\nkm.fit(tfidf_matrix)\ncategories= km.labels_.tolist()\npreprocessed_reviews['cluster'] = km.labels_"},"cell_type":"code","id":"2902b840-6b2b-4600-ac0d-0a277f866a1b","outputs":[],"execution_count":107},{"source":"from collections import Counter\ndef most_freq_term(text):\n    tokens = text.split()\n    term_count = Counter(tokens)\n    most_common_term, most_common_count = term_count.most_common(1)[0]\n    return most_common_term, most_common_count\n    \n\ntopic_terms = preprocessed_reviews.groupby('cluster')['content'].apply(lambda texts: most_freq_term(' '.join(texts))).reset_index()\n\n\ntopic_terms = pd.DataFrame(topic_terms['content'].tolist(), columns=['most_frequent_term', 'term_count'])\ntopic_terms['cluster'] = topic_terms.index\n\ntopic_terms = topic_terms[['cluster', 'most_frequent_term', 'term_count']]\n\nprint(topic_terms)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1721153448945,"lastExecutedByKernel":"f96bf642-a079-4c11-9bbd-c9865b11a9d9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from collections import Counter\ndef most_freq_term(text):\n    tokens = text.split()\n    term_count = Counter(tokens)\n    most_common_term, most_common_count = term_count.most_common(1)[0]\n    return most_common_term, most_common_count\n    \n\ntopic_terms = preprocessed_reviews.groupby('cluster')['content'].apply(lambda texts: most_freq_term(' '.join(texts))).reset_index()\n\n\ntopic_terms = pd.DataFrame(topic_terms['content'].tolist(), columns=['most_frequent_term', 'term_count'])\ntopic_terms['cluster'] = topic_terms.index\n\ntopic_terms = topic_terms[['cluster', 'most_frequent_term', 'term_count']]\n\nprint(topic_terms)","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"4e818f2e-2a3b-4e29-9125-f0157b5676a9","outputs":[{"output_type":"stream","name":"stdout","text":"   cluster most_frequent_term  term_count\n0        0                app        2159\n1        1                app         573\n2        2               good          95\n3        3           calendar         486\n4        4             remind         456\n"}],"execution_count":108}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}